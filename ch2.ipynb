{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# ch2 - Core operations with spaCy"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "* Overview of spaCy conventions\n",
    "* Introducing tokenization\n",
    "* Understanding lemmatization\n",
    "* spaCy container objects\n",
    "* More spaCy features"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "doc = nlp(\"I went there\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Introducing tokenization"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "doc = nlp(\"I own a ginger cat.\")\n",
    "print([token.text for token in doc])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['I', 'own', 'a', 'ginger', 'cat', '.']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "doc = nlp(\"It's been a crazy week!!!\")\n",
    "print([token.text for token in doc])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['It', \"'s\", 'been', 'a', 'crazy', 'week', '!', '!', '!']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Customizing the tokenizer"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "import spacy\n",
    "from spacy.symbols import ORTH\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "doc = nlp(\"lemme that\")\n",
    "print([w.text for w in doc])\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['lemme', 'that']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# define special case\n",
    "special_case = [{ORTH: \"lem\"}, {ORTH: \"me\"}]\n",
    "nlp.tokenizer.add_special_case(\"lemme\", special_case)\n",
    "print([w.text for w in nlp(\"lemme that\")])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['lem', 'me', 'that']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "print([w.text for w in nlp(\"lemme!\")])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['lem', 'me', '!']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "nlp.tokenizer.add_special_case(\"...lemme...?\", [{ORTH: \"...lemme...?\"}])\n",
    "print([w.text for w in nlp(\"...lemme...?\")])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['...lemme...?']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Debugging the tokenizer"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "text = \"Let's go!\"\n",
    "doc = nlp(text)\n",
    "tok_exp = nlp.tokenizer.explain(text)\n",
    "for t in tok_exp:\n",
    "    print(t[1], \"\\t\", t[0])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Let \t SPECIAL-1\n",
      "'s \t SPECIAL-2\n",
      "go \t TOKEN\n",
      "! \t SUFFIX\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Sentence segmentation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import spacy\n"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "interpreter": {
   "hash": "e774977668b7c0ae8309835a5187aa7fbf7669e7d0bb59755bc63e573643edcd"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}